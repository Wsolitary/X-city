import sys
import cv2
import mediapipe as mp
import numpy as np
import time
import requests
import os
import random
import json
import uuid
import pandas as pd
from datetime import datetime, timedelta
from PyQt6.QtWidgets import (QApplication, QWidget, QLabel, QVBoxLayout, 
                             QHBoxLayout, QMenu, QSystemTrayIcon, QPushButton)
from PyQt6.QtCore import Qt, QThread, pyqtSignal, QTimer, QPoint, QPropertyAnimation, QEasingCurve
from PyQt6.QtGui import QPainter, QColor, QFont, QAction, QIcon, QBrush, QPen, QCursor

# ================= é…ç½®ä¸å¸¸é‡ =================
LEFT_EYE = [362, 385, 387, 263, 373, 380]
RIGHT_EYE = [33, 160, 158, 133, 153, 144]
MOUTH = [61, 291, 39, 181, 0, 17] 
MAR_THRESHOLD = 0.6
CONSECUTIVE_FRAMES = 10

# æ•°æ®å­˜å‚¨è·¯å¾„ - Fç›˜ä¸“å±
DATA_DIR = r"F:\Vigil\data"
LOG_FILE = os.path.join(DATA_DIR, "focus_history.csv")
REPORT_FILE = os.path.join(DATA_DIR, "reports.json")

# API é…ç½®
API_KEY = "sk-y8LGmh4LtgB3A2Dy5kRL9NZbXfdhWdLNpz8zT2v92Z2OTDv2"
API_URL = "https://api.moonshot.cn/v1/chat/completions"

SYSTEM_PROMPT = {
    "role": "system", 
    "content": (
        "ä½ æ˜¯ CodeVigilante ç³»ç»Ÿçš„å¥åº·å®ˆæŠ¤ AIï¼Œä»£å· 'Vigil'ã€‚"
        "1. å½“ç”¨æˆ·ç–²åŠ³æ—¶ï¼šç”¨å…³æ€€ä½†åšå®šçš„è¯­æ°”åŠå¯¼ä¼‘æ¯ã€‚**ä¸¥ç¦é‡å¤ç›¸åŒçš„è¯æœ¯**ã€‚"
        "2. å½“ç”¨æˆ·ä¸“æ³¨æ—¶ï¼šç»™äºˆæç®€çš„è‚¯å®šï¼Œæˆ–è€…ä¿æŒæ²‰é»˜ã€‚"
        "3. ä½ çš„ç›®æ ‡æ˜¯è®©ç”¨æˆ·ä¿æŒå¯æŒç»­çš„é«˜æ•ˆã€‚"
        "å›å¤é™åˆ¶åœ¨ 30 å­—ä»¥å†…ã€‚"
    )
}

# ================= ä¼˜åŒ–åçš„ EAR ç®—æ³•ç±» =================
class AdaptiveEARTracker:
    def __init__(self, calibration_seconds=30):
        self.calibration_seconds = calibration_seconds
        self.baseline_ear_sum = 0.0
        self.baseline_count = 0
        self.is_calibrating = True
        self.calibration_start_time = time.time()
        
        # ä¸ªäººåŒ–é˜ˆå€¼ï¼ˆåˆå§‹å€¼ï¼Œä¼šåœ¨æ ¡å‡†åæ›´æ–°ï¼‰
        self.personal_threshold = 0.22
        self.personal_baseline = 0.3
        self.focused_threshold = 0.3  # æ–°å¢ï¼šä¸“æ³¨é˜ˆå€¼
        
    def update(self, current_ear):
        """æ›´æ–° EAR çŠ¶æ€ï¼Œè¿”å› (is_drowsy, confidence)"""
        current_time = time.time()
        
        # æ ¡å‡†é˜¶æ®µï¼šæ”¶é›†ä¸ªäººåŸºå‡†æ•°æ®
        if self.is_calibrating and (current_time - self.calibration_start_time) < self.calibration_seconds:
            self.baseline_ear_sum += current_ear
            self.baseline_count += 1
            
            # å®æ—¶æ›´æ–°é˜ˆå€¼ï¼ˆåŸºäºå½“å‰å¹³å‡å€¼ï¼‰
            if self.baseline_count > 10:  # è‡³å°‘æœ‰10ä¸ªæ ·æœ¬
                self.personal_baseline = self.baseline_ear_sum / self.baseline_count
                self.personal_threshold = self.personal_baseline * 0.75  # è°ƒæ•´æ•æ„Ÿåº¦ï¼šåŸºå‡†çš„75%å³è§†ä¸ºç–²åŠ³ (0.7å¤ªéš¾è§¦å‘, 0.8å¤ªæ˜“è§¦å‘)
                self.focused_threshold = self.personal_baseline * 1.0   # é™ä½éš¾åº¦ï¼šè¾¾åˆ°åŸºå‡†å€¼å³è§†ä¸ºä¸“æ³¨
            
            return False, 0.5  # æ ¡å‡†ä¸­ï¼Œä¸ç¡®å®šçŠ¶æ€
        
        # æ ¡å‡†å®Œæˆ
        if self.is_calibrating:
            self.is_calibrating = False
            if self.baseline_count > 0:
                self.personal_baseline = self.baseline_ear_sum / self.baseline_count
                self.personal_threshold = self.personal_baseline * 0.75
                self.focused_threshold = self.personal_baseline * 1.0
                print(f"âœ… ä¸ªäººåŒ–æ ¡å‡†å®Œæˆï¼")
                print(f"   åŸºå‡†EAR: {self.personal_baseline:.3f}")
                print(f"   ä¸“æ³¨é˜ˆå€¼: > {self.focused_threshold:.3f}")
                print(f"   ç–²åŠ³é˜ˆå€¼: < {self.personal_threshold:.3f}")
        
        # ä½¿ç”¨ä¸ªäººåŒ–é˜ˆå€¼åˆ¤æ–­ç–²åŠ³
        # ä¼˜åŒ–ï¼šåŠ å…¥é˜²æŠ–åŠ¨ï¼Œåªæœ‰è¿ç»­å¤šå¸§ä½ EAR æ‰ç®—ç–²åŠ³ï¼Œé¿å…ç›®å…‰åç§»é€ æˆçš„è¯¯åˆ¤
        # ä¸”é™ä½çµæ•åº¦ï¼šä» 0.75 é™åˆ° 0.65 (åªæœ‰æ˜æ˜¾é—­çœ¼æˆ–æåº¦çœ¯çœ¼æ‰è§¦å‘)
        if self.is_calibrating:
             pass # æ ¡å‡†æ—¶ä¸ä¿®æ”¹é˜ˆå€¼
        elif self.baseline_count > 0:
             # è¿è¡Œæ—¶åŠ¨æ€å¾®è°ƒï¼šå¦‚æœç”¨æˆ·è§‰å¾—å¤ªæ•æ„Ÿï¼Œæˆ‘ä»¬æ‰‹åŠ¨é™ä½ç³»æ•°
             self.personal_threshold = self.personal_baseline * 0.65
        
        is_drowsy = current_ear < self.personal_threshold
        
        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆç¦»é˜ˆå€¼è¶Šè¿œï¼Œç½®ä¿¡åº¦è¶Šé«˜ï¼‰
        if is_drowsy:
            # ç–²åŠ³åŒºé—´ï¼š0 åˆ° threshold
            confidence = min(0.95, (self.personal_threshold - current_ear) / self.personal_threshold)
        else:
            confidence = 0.0
        
        return is_drowsy, confidence

# æ»‘åŠ¨å¹³å‡æ»¤æ³¢å™¨
class MovingAverageFilter:
    def __init__(self, window_size=10):
        self.window_size = window_size
        self.values = []
    
    def update(self, value):
        self.values.append(value)
        if len(self.values) > self.window_size:
            self.values.pop(0)
        return sum(self.values) / len(self.values) if self.values else value

# ================= æ ¸å¿ƒç®—æ³• =================
def calculate_ear(landmarks, indices):
    try:
        points = np.array([[landmarks[i].x, landmarks[i].y] for i in indices])
        A = np.linalg.norm(points[1] - points[5])
        B = np.linalg.norm(points[2] - points[4])
        C = np.linalg.norm(points[0] - points[3])
        return (A + B) / (2.0 * C)
    except: return 0.0

def calculate_mar(landmarks, indices):
    try:
        points = np.array([[landmarks[i].x, landmarks[i].y] for i in indices])
        A = np.linalg.norm(points[2] - points[3])
        B = np.linalg.norm(points[4] - points[5])
        C = np.linalg.norm(points[0] - points[1])
        return (A + B) / (2.0 * C)
    except: return 0.0

def ensure_data_dir():
    if not os.path.exists(DATA_DIR):
        try: os.makedirs(DATA_DIR)
        except: pass

def log_data(status_label, ear, mar):
    ensure_data_dir()
    now = datetime.now()
    data = {
        "timestamp": now.strftime("%Y-%m-%d %H:%M:%S"),
        "date": now.strftime("%Y-%m-%d"),
        "status": status_label,
        "ear": round(ear, 3),
        "mar": round(mar, 3)
    }
    df = pd.DataFrame([data])
    if not os.path.exists(LOG_FILE):
        df.to_csv(LOG_FILE, index=False, mode='w')
    else:
        df.to_csv(LOG_FILE, index=False, mode='a', header=False)

# ================= çº¿ç¨‹ç±» =================
class AIThread(QThread):
    response_received = pyqtSignal(str)

    def __init__(self, user_msg):
        super().__init__()
        self.user_msg = user_msg

    def run(self):
        try:
            messages = [SYSTEM_PROMPT, {"role": "user", "content": self.user_msg}]
            data = {"model": "moonshot-v1-8k", "messages": messages, "temperature": 0.7}
            headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
            response = requests.post(API_URL, headers=headers, json=data, timeout=10)
            if response.status_code == 200:
                reply = response.json()['choices'][0]['message']['content']
                self.response_received.emit(reply)
        except:
            pass

class ReportThread(QThread):
    finished = pyqtSignal(str) # è¿”å›ç”ŸæˆçŠ¶æ€æ¶ˆæ¯

    def run(self):
        # 1. è¯»å–æ•°æ®
        if not os.path.exists(LOG_FILE): return
        try:
            df = pd.read_csv(LOG_FILE)
            if df.empty: return
            
            df['datetime'] = pd.to_datetime(df['timestamp'])
            last_time = df['datetime'].max()
            start_time = last_time - timedelta(minutes=30)
            df_recent = df[df['datetime'] >= start_time]
            
            if df_recent.empty: return

            # ç»Ÿè®¡æŒ‡æ ‡
            rec_total = len(df_recent)
            rec_focused = len(df_recent[df_recent['status'] == 'Focused'])
            rec_drowsy = len(df_recent[df_recent['status'].isin(['Drowsy', 'Yawning'])])
            rec_ear = df_recent['ear'].mean()

            # æ„å»º Prompt
            prompt = (
                f"è¯·åˆ†æç”¨æˆ·æœ€è¿‘30åˆ†é’Ÿçš„ç²¾åŠ›çŠ¶æ€ (è‡ªåŠ¨å®šæœŸæŠ¥å‘Š)ï¼š\n"
                f"- è®°å½•æ—¶é•¿: {rec_total * 5 // 60} åˆ†é’Ÿ\n"
                f"- ä¸“æ³¨æ—¶é•¿: {rec_focused * 5 // 60} åˆ†é’Ÿ\n"
                f"- ç–²åŠ³/æ‰“å“ˆæ¬ æ¬¡æ•°: {rec_drowsy} æ¬¡\n"
                f"- å¹³å‡ä¸“æ³¨åº¦(EAR): {rec_ear:.3f}\n\n"
                f"è¯·ç»™å‡ºç®€çŸ­çš„å½“å‰çŠ¶æ€è¯„ä¼°å’Œæ¥ä¸‹æ¥çš„è¡ŒåŠ¨å»ºè®®ã€‚"
            )

            # è°ƒç”¨ API
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ Vigil ç³»ç»Ÿçš„æ™ºèƒ½æ•ˆèƒ½åˆ†æå¸ˆã€‚"},
                {"role": "user", "content": prompt}
            ]
            data = {"model": "moonshot-v1-8k", "messages": messages, "temperature": 0.7}
            headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
            
            response = requests.post(API_URL, headers=headers, json=data, timeout=30)
            if response.status_code == 200:
                content = response.json()['choices'][0]['message']['content']
                
                # è¯»å–æ—§æŠ¥å‘Š
                reports = []
                if os.path.exists(REPORT_FILE):
                    try:
                        with open(REPORT_FILE, 'r', encoding='utf-8') as f:
                            reports = json.load(f)
                    except: pass
                
                # æ·»åŠ æ–°æŠ¥å‘Š
                new_report = {
                    "id": str(uuid.uuid4()),
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "type": "30min",
                    "content": content
                }
                reports.insert(0, new_report)
                
                # å†™å…¥æ–‡ä»¶
                with open(REPORT_FILE, 'w', encoding='utf-8') as f:
                    json.dump(reports, f, ensure_ascii=False, indent=2)
                    
                self.finished.emit("ğŸ“ å·²è‡ªåŠ¨ç”Ÿæˆ 30åˆ†é’Ÿæ•ˆèƒ½æŠ¥å‘Š")
        except Exception as e:
            print(f"Auto report failed: {e}")

class VideoThread(QThread):
    status_update = pyqtSignal(str, float, float) # status, ear, mar
    
    def __init__(self):
        super().__init__()
        self.running = True
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1, refine_landmarks=True, 
            min_detection_confidence=0.5, min_tracking_confidence=0.5
        )
        # åˆå§‹åŒ–ä¼˜åŒ–ç®—æ³•
        self.ear_tracker = AdaptiveEARTracker(calibration_seconds=30)
        self.ear_filter = MovingAverageFilter(window_size=10)

    def run(self):
        cap = cv2.VideoCapture(0)
        frame_counter = 0
        last_log_time = time.time()
        data_buffer = {"ear": [], "mar": [], "status": []}

        while self.running:
            ret, frame = cap.read()
            if not ret:
                time.sleep(1)
                self.status_update.emit("No Face", 0.0, 0.0)
                continue

            img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.face_mesh.process(img_rgb)
            
            status = "No Face"
            ear = 0.0
            mar = 0.0

            if results.multi_face_landmarks:
                for face_landmarks in results.multi_face_landmarks:
                    landmarks = face_landmarks.landmark
                    
                    # è®¡ç®—åŸå§‹ EAR
                    raw_ear = (calculate_ear(landmarks, LEFT_EYE) + calculate_ear(landmarks, RIGHT_EYE)) / 2.0
                    
                    # åº”ç”¨æ»‘åŠ¨å¹³å‡æ»¤æ³¢
                    filtered_ear = self.ear_filter.update(raw_ear)
                    
                    # ä½¿ç”¨è‡ªé€‚åº”ç®—æ³•åˆ¤æ–­ç–²åŠ³
                    is_drowsy, confidence = self.ear_tracker.update(filtered_ear)
                    
                    mar = calculate_mar(landmarks, MOUTH)

                    # çŠ¶æ€åˆ¤å®šé€»è¾‘
                    # ç–²åŠ³åˆ¤å®šï¼šAdaptiveEARTracker è¯´æ˜¯ç–²åŠ³ï¼Œä¸”å¿…é¡»è¿ç»­å¤šå¸§ç¡®è®¤ (é˜²æŠ–)
                    # CONSECUTIVE_FRAMES åŸä¸º10 (çº¦0.5ç§’)ï¼Œå¢åŠ åˆ° 20 (çº¦1ç§’)ï¼Œè¿‡æ»¤çŸ­æš‚ä½å¤´æˆ–çœ¨çœ¼
                    if is_drowsy: 
                        frame_counter += 1
                    else:
                        frame_counter = 0
                    
                    if frame_counter >= 20: # æé«˜åˆ¤å®šé—¨æ§›
                        status = "Drowsy"
                    elif mar > MAR_THRESHOLD:
                        status = "Yawning"
                    elif filtered_ear > self.ear_tracker.focused_threshold: # ä½¿ç”¨åŠ¨æ€ä¸“æ³¨é˜ˆå€¼
                        status = "Focused"
                    else:
                        status = "Normal"
                    
                    ear = filtered_ear
                    
                    # ç¼“å†²æ•°æ®
                    data_buffer["ear"].append(ear)
                    data_buffer["mar"].append(mar)
                    data_buffer["status"].append(status)

            # å‘é€ä¿¡å·æ›´æ–° UI
            self.status_update.emit(status, ear, mar)

            # æ•°æ®è®°å½• (5ç§’èšåˆ)
            current_time = time.time()
            if current_time - last_log_time > 5.0:
                if data_buffer["ear"]:
                    avg_ear = sum(data_buffer["ear"]) / len(data_buffer["ear"])
                    avg_mar = sum(data_buffer["mar"]) / len(data_buffer["mar"])
                    from collections import Counter
                    most_common = Counter(data_buffer["status"]).most_common(1)[0][0]
                    log_data(most_common, avg_ear, avg_mar)
                
                data_buffer = {"ear": [], "mar": [], "status": []}
                last_log_time = current_time

            time.sleep(0.05) # é™ä½ CPU å ç”¨

        cap.release()

    def stop(self):
        self.running = False
        self.wait()

# ================= UI ç±» =================
class BubbleLabel(QLabel):
    def __init__(self, target_widget=None):
        super().__init__(None) # è®¾ç½®ä¸ºé¡¶çº§çª—å£ï¼Œé¿å…è¢«çˆ¶çª—å£è£å‰ª
        self.target = target_widget
        self.setWindowFlags(Qt.WindowType.FramelessWindowHint | Qt.WindowType.WindowStaysOnTopHint | Qt.WindowType.Tool)
        self.setAttribute(Qt.WidgetAttribute.WA_TranslucentBackground)
        
        self.setStyleSheet("""
            QLabel {
                background-color: rgba(255, 255, 255, 240);
                color: #333333;
                border-radius: 10px;
                padding: 12px;
                border: 2px solid #3498db;
                font-family: 'Microsoft YaHei';
                font-size: 14px;
                font-weight: bold;
            }
        """)
        self.setWordWrap(True) # å…è®¸æ¢è¡Œ
        self.setMaximumWidth(250) # é™åˆ¶æœ€å¤§å®½åº¦
        self.hide()
        
        # è‡ªåŠ¨æ¶ˆå¤±å®šæ—¶å™¨
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.hide)

    def show_message(self, text, duration=5000):
        self.setText(text)
        self.adjustSize()
        
        # æ™ºèƒ½å®šä½ï¼šä¼˜å…ˆæ˜¾ç¤ºåœ¨å·¦ä¾§ï¼Œå¦‚æœå·¦ä¾§ä¸å¤Ÿæ˜¾ç¤ºåœ¨å³ä¾§
        if self.target:
            target_geo = self.target.geometry()
            screen_geo = QApplication.primaryScreen().geometry()
            
            # å°è¯•æ”¾åœ¨å·¦ä¾§
            x = target_geo.x() - self.width() - 15
            y = target_geo.y()
            
            # å¦‚æœå·¦ä¾§è¶…å‡ºå±å¹• (å³ x < 0)ï¼Œåˆ™æ”¾åœ¨å³ä¾§
            if x < 0:
                x = target_geo.x() + target_geo.width() + 15
                
            # é˜²æ­¢åº•éƒ¨æº¢å‡º
            if y + self.height() > screen_geo.height():
                y = screen_geo.height() - self.height() - 10
                
            self.move(x, y)
            
        self.show()
        self.timer.start(duration)

class DesktopPet(QWidget):
    def __init__(self):
        super().__init__()
        self.initUI()
        self.initLogic()
        
    def initUI(self):
        self.setWindowFlags(Qt.WindowType.FramelessWindowHint | Qt.WindowType.WindowStaysOnTopHint | Qt.WindowType.Tool)
        self.setAttribute(Qt.WidgetAttribute.WA_TranslucentBackground)
        self.resize(100, 100) # åˆå§‹å¤§å°
        
        # çŠ¶æ€æŒ‡ç¤ºé¢œè‰²
        self.current_color = QColor(200, 200, 200) # é»˜è®¤ç°è‰²
        self.status_text = "..."

        # æ°”æ³¡ (ä¼ å…¥ self ä½œä¸ºå®šä½ç›®æ ‡)
        self.bubble = BubbleLabel(self)
        
        # ç§»åŠ¨ç›¸å…³
        self.dragging = False
        self.offset = QPoint()

        # å³é”®èœå•
        self.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.customContextMenuRequested.connect(self.show_menu)
        
        # æ”¾åˆ°å±å¹•å³ä¸‹è§’
        screen = QApplication.primaryScreen().geometry()
        self.move(screen.width() - 150, screen.height() - 200)

    def initLogic(self):
        # æ˜¾ç¤ºå¯åŠ¨æç¤º
        self.bubble.show_message("ğŸ‘‹ å—¨ï¼è¯·æ­£å¸¸ççœ¼ï¼Œçœ¨çœ¼30ç§’è¿›è¡Œæ ¡å‡†...", 5000)
        
        # è§†é¢‘çº¿ç¨‹
        self.video_thread = VideoThread()
        self.video_thread.status_update.connect(self.update_status)
        self.video_thread.start()
        
        # è‡ªåŠ¨å·¡èˆªè®¡æ—¶å™¨
        self.check_timer = QTimer(self)
        self.check_timer.timeout.connect(self.auto_check)
        self.check_timer.start(5000) # æ”¹ä¸ºæ¯5ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œä»¥ä¾¿æ›´åŠæ—¶åœ°æ•æ‰çŠ¶æ€
        
        self.last_ear = 0.0
        self.last_mar = 0.0
        self.current_status = "Normal"
        
        # å†å²çŠ¶æ€è®°å½• (ç”¨äºè¶‹åŠ¿åˆ†æ)
        self.status_history = []  # å­˜å‚¨ (timestamp, status)
        self.last_ai_trigger_time = 0 # ä¸Šæ¬¡è§¦å‘ AI çš„æ—¶é—´
        self.last_report_time = time.time() # ä¸Šæ¬¡ç”ŸæˆæŠ¥å‘Šçš„æ—¶é—´
        
        # å…æ‰“æ‰°é€»è¾‘
        self.focused_start_time = None
        self.in_dnd_mode = False
        self.dnd_threshold = 60 # è¿ç»­ä¸“æ³¨60ç§’è¿›å…¥å…æ‰“æ‰° 
        
        # æ ¡å‡†çŠ¶æ€è¿½è¸ª
        self.is_calibrating = True
        self.calibration_timer = QTimer(self)
        self.calibration_timer.timeout.connect(self.check_calibration_status)
        self.calibration_timer.start(1000) # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡æ ¡å‡†çŠ¶æ€

    def paintEvent(self, event):
        painter = QPainter(self)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)
        
        # ç»˜åˆ¶åœ†å½¢èƒŒæ™¯
        painter.setBrush(QBrush(self.current_color))
        painter.setPen(Qt.PenStyle.NoPen)
        painter.drawEllipse(10, 10, 60, 60)
        
        # ç»˜åˆ¶çœ¼ç› (ç®€å•çš„æ‹ŸäººåŒ–)
        painter.setBrush(QBrush(Qt.GlobalColor.white))
        painter.drawEllipse(25, 30, 10, 10) # å·¦çœ¼
        painter.drawEllipse(45, 30, 10, 10) # å³çœ¼
        
        painter.setBrush(QBrush(Qt.GlobalColor.black))
        # æ ¹æ®çŠ¶æ€æ”¹å˜çœ¼çƒä½ç½®/å¤§å°
        if self.current_status == "Drowsy":
            # é—­çœ¼
            painter.setPen(QPen(Qt.GlobalColor.black, 2))
            painter.drawLine(25, 35, 35, 35)
            painter.drawLine(45, 35, 55, 35)
        else:
            painter.drawEllipse(27, 32, 5, 5)
            painter.drawEllipse(47, 32, 5, 5)
        
        # æ·»åŠ çŠ¶æ€æ–‡å­—
        # ä¼˜åŒ–ï¼šæ ¡å‡†æ¨¡å¼(é»„è‰²)ä¸‹ç”¨é»‘è‰²æ–‡å­—ï¼Œå¦åˆ™ç™½è‰²
        if self.current_status == "Calibrating":
            painter.setPen(QPen(Qt.GlobalColor.black, 2))
        else:
            painter.setPen(QPen(Qt.GlobalColor.white, 2))
            
        painter.setFont(QFont("Microsoft YaHei", 10, QFont.Weight.Bold))
        
        # æ ¹æ®çŠ¶æ€æ˜¾ç¤ºä¸åŒæ–‡å­—
        if self.current_status == "Calibrating":
            text = "æ ¡å‡†ä¸­..."
        elif self.current_status == "Drowsy":
            text = "ç–²åŠ³è­¦å‘Š"
        elif self.current_status == "Yawning":
            text = "æ­£åœ¨æ‰“å“ˆæ¬ "
        elif self.current_status == "Focused":
            text = "ä¸“æ³¨ä¸­"
        elif self.current_status == "Normal":
            text = "çŠ¶æ€æ­£å¸¸"
        else:
            text = "çŠ¶æ€æ­£å¸¸" 
        
        # è®¡ç®—æ–‡å­—ä½ç½®ï¼ˆå±…ä¸­ï¼‰
        text_rect = painter.fontMetrics().boundingRect(text)
        text_x = (80 - text_rect.width()) // 2
        text_y = 85
        
        painter.drawText(text_x, text_y, text)

    def update_status(self, status, ear, mar):
        # ä¼˜å…ˆå¤„ç†æ ¡å‡†çŠ¶æ€
        is_calibrating = False
        if hasattr(self, 'video_thread') and hasattr(self.video_thread, 'ear_tracker'):
            is_calibrating = self.video_thread.ear_tracker.is_calibrating

        if is_calibrating:
            self.last_ear = ear
            self.last_mar = mar
            
          
            self.current_status = "Calibrating"
            self.current_color = QColor(255, 255, 0)
            
            # æ§åˆ¶å°è¾“å‡º
            timestamp = datetime.now().strftime("%H:%M:%S")
            print(f"[{timestamp}] [æ ¡å‡†ä¸­] çŠ¶æ€: {status} | EAR: {ear:.3f} | MAR: {mar:.3f}")
            self.update()
            return

        self.current_status = status
        self.last_ear = ear
        self.last_mar = mar
        
        # æ§åˆ¶å°è¾“å‡º
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] çŠ¶æ€: {status} | EAR: {ear:.3f} | MAR: {mar:.3f}")
        
        # è®°å½•å†å²çŠ¶æ€ (ç”¨äº15åˆ†é’Ÿè¶‹åŠ¿åˆ†æ)
        self.status_history.append((time.time(), status))
        
        # è¿½è¸ªä¸“æ³¨æ—¶é—´
        if status == "Focused":
            if self.focused_start_time is None:
                self.focused_start_time = time.time()
            elif time.time() - self.focused_start_time > self.dnd_threshold and not self.in_dnd_mode:
                self.in_dnd_mode = True
                # è¿›å…¥å…æ‰“æ‰°æ—¶æç¤ºä¸€ä¸‹
                self.bubble.show_message("ğŸŒ™ è¿›å…¥æ·±åº¦å…æ‰“æ‰°æ¨¡å¼", 3000)
        else:
            # çŠ¶æ€ä¸­æ–­ï¼Œé‡ç½®è®¡æ—¶
            # åªæœ‰å½“çŠ¶æ€å˜æˆâ€œç–²åŠ³â€æˆ–â€œæ‰“å“ˆæ¬ â€æ—¶æ‰æ‰“æ–­ï¼Œå¦‚æœæ˜¯å¶å°”çš„â€œNormalâ€å¯ä»¥å®¹å¿ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºä¸€å¾‹æ‰“æ–­ï¼‰
            if status != "Normal": # å…è®¸çŸ­æš‚çš„ Normal çŠ¶æ€ä¸æ‰“æ–­å¿ƒæµ
                self.focused_start_time = None
                if self.in_dnd_mode:
                    self.in_dnd_mode = False
                    self.bubble.show_message("â˜€ï¸ é€€å‡ºå…æ‰“æ‰°æ¨¡å¼", 3000)
        
        if status == "Drowsy":
            self.current_color = QColor(255, 80, 80) # çº¢
            self.setToolTip("è­¦å‘Šï¼šç–²åŠ³ï¼")
        elif status == "Yawning":
            self.current_color = QColor(255, 165, 0) # æ©™
            self.setToolTip("æ­£åœ¨æ‰“å“ˆæ¬ ")
        elif status == "Focused":
            self.current_color = QColor(100, 255, 100) # ç»¿
            if self.in_dnd_mode:
                 self.setToolTip("é«˜åº¦ä¸“æ³¨ (å…æ‰“æ‰°ä¸­)")
                 # å…æ‰“æ‰°æ¨¡å¼ä¸‹ï¼Œé¢œè‰²ç¨å¾®å˜æ·±ä¸€ç‚¹ï¼Œè¡¨ç¤ºæ²‰æµ¸
                 self.current_color = QColor(0, 200, 0)
            else:
                 self.setToolTip("é«˜åº¦ä¸“æ³¨")
        elif status == "Normal":
            self.current_color = QColor(100, 200, 255) # è“
            self.setToolTip("çŠ¶æ€æ­£å¸¸")
        else:
            self.current_color = QColor(200, 200, 200) # ç°
            self.setToolTip("æœªæ£€æµ‹åˆ°äººè„¸")
            
        self.update() # é‡ç»˜

    def check_calibration_status(self):
        """æ£€æŸ¥æ ¡å‡†çŠ¶æ€å¹¶æ›´æ–°æ˜¾ç¤º"""
        if hasattr(self.video_thread, 'ear_tracker'):
            tracker = self.video_thread.ear_tracker
            
            # å¦‚æœè¿˜åœ¨æ ¡å‡†çŠ¶æ€
            if tracker.is_calibrating:
                elapsed = time.time() - tracker.calibration_start_time
                remaining = max(0, 30 - int(elapsed))
                
                # å®‰å…¨ç½‘ï¼šå¦‚æœè¶…è¿‡32ç§’è¿˜æ²¡ç»“æŸï¼ˆè¯´æ˜å¯èƒ½æ²¡äººè„¸å¯¼è‡´ update æ²¡è¢«è°ƒç”¨ï¼‰ï¼Œå¼ºåˆ¶ç»“æŸ
                if elapsed > 32:
                    print("âš ï¸ æ ¡å‡†è¶…æ—¶ï¼Œå¼ºåˆ¶ç»“æŸæ ¡å‡†...")
                    tracker.is_calibrating = False
                    # å†æ¬¡è°ƒç”¨ä»¥è¿›å…¥ else åˆ†æ”¯
                    self.check_calibration_status()
                    return

                # æ›´æ–°æ‚¬æµ®çª—æ˜¾ç¤º
                self.current_status = "Calibrating"
                self.current_color = QColor(255, 255, 0)  # é»„è‰²è¡¨ç¤ºæ ¡å‡†ä¸­
                self.setToolTip(f"æ ¡å‡†ä¸­... å‰©ä½™ {remaining} ç§’")
                self.update()  # å¼ºåˆ¶é‡ç»˜
                
                # æ¯10ç§’æ›´æ–°ä¸€æ¬¡æç¤º
                if remaining % 10 == 0 and remaining > 0:
                    self.bubble.show_message(f"ğŸ”„ æ ¡å‡†ä¸­... è¯·ä¿æŒæ­£å¸¸çœ¨çœ¼ï¼Œå‰©ä½™ {remaining} ç§’", 3000)
                return

        # æ ¡å‡†å®Œæˆ (æˆ–è€… ear_tracker ä¸å­˜åœ¨)
        if hasattr(self, 'calibration_timer'):
            self.calibration_timer.stop()
        
        self.bubble.show_message("âœ… æ ¡å‡†å®Œæˆï¼Vigil å·²å°±ç»ª", 3000)
        self.current_status = "Normal"  # é‡ç½®ä¸ºæ­£å¸¸çŠ¶æ€
        self.update()  # å¼ºåˆ¶é‡ç»˜

    def auto_check(self):
        """æ™ºèƒ½åˆ†æé€»è¾‘ï¼šåŸºäºæœ€è¿‘15åˆ†é’Ÿçš„æ•°æ®è¿›è¡Œ AI å¹²é¢„"""
        current_time = time.time()
        
        # 1. æ¸…ç†è¿‡æœŸæ•°æ® (ä¿ç•™æœ€è¿‘15åˆ†é’Ÿ / 900ç§’)
        cutoff_time = current_time - 900
        # ç®€å•ä¼˜åŒ–ï¼šå¦‚æœåˆ—è¡¨å¤ªé•¿ï¼Œå…ˆä»å¤´æ¸…ç†
        while self.status_history and self.status_history[0][0] < cutoff_time:
            self.status_history.pop(0)
            
        # 2. è®¡ç®—å„çŠ¶æ€æŒç»­æ—¶é—´
        drowsy_duration = 0.0
        focused_duration = 0.0
        
        # åªæœ‰å½“æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®æ—¶æ‰è®¡ç®—
        if len(self.status_history) > 1:
            # éå†å†å²è®°å½•è®¡ç®—æ—¶é•¿ (ç®€å•çš„ç§¯åˆ†ï¼šæ—¶é—´å·® * çŠ¶æ€)
            # æ³¨æ„ï¼šstatus_history æ˜¯ (timestamp, status
            for i in range(len(self.status_history) - 1):
                t1, s1 = self.status_history[i]
                t2, _ = self.status_history[i+1]
                dt = t2 - t1
                
                # è¿‡æ»¤å¼‚å¸¸çš„å¤§é—´éš” (æ¯”å¦‚ç¨‹åºå¡é¡¿æˆ–ä¼‘çœ )ï¼Œé™åˆ¶æœ€å¤§é—´éš”ä¸º 1ç§’
                if dt > 1.0: dt = 0.05
                
                if s1 in ["Drowsy", "Yawning"]:
                    drowsy_duration += dt
                elif s1 == "Focused":
                    focused_duration += dt

        # 3. è§¦å‘é€»è¾‘
        # åªæœ‰è·ç¦»ä¸Šæ¬¡è§¦å‘è¶…è¿‡ 5åˆ†é’Ÿ (300ç§’) æ‰å…è®¸å†æ¬¡è§¦å‘ï¼Œé¿å…å” å¨
        # ä¾‹å¤–ï¼šå¦‚æœæ­£åœ¨æ‰“å“ˆæ¬ ï¼Œä¸”è·ç¦»ä¸Šæ¬¡è§¦å‘è¶…è¿‡ 1åˆ†é’Ÿï¼Œå¯ä»¥è§¦å‘
        
        msg = ""
        trigger = False
        
        time_since_last = current_time - self.last_ai_trigger_time
        
        # ä¼˜å…ˆçº§ 1: ä¸¥é‡ç–²åŠ³è¶‹åŠ¿ (15åˆ†é’Ÿå†…ç´¯è®¡ > 10åˆ†é’Ÿ / 600ç§’)
        # ä¸ºäº†æ¼”ç¤ºæ•ˆæœï¼Œè¿™é‡Œå…ˆæŠŠé˜ˆå€¼è®¾ä½ä¸€ç‚¹ï¼Œæ¯”å¦‚ 1åˆ†é’Ÿ (60ç§’) æ–¹ä¾¿æµ‹è¯•ï¼Œ
        # å®é™…ä½¿ç”¨è¯·æ”¹ä¸º 600 (10åˆ†é’Ÿ)
        FATIGUE_THRESHOLD = 600 # 10åˆ†é’Ÿ
        FOCUS_THRESHOLD = 600   # 10åˆ†é’Ÿ
        
        if drowsy_duration > FATIGUE_THRESHOLD and time_since_last > 300:
            minutes = int(drowsy_duration / 60)
            msg = f"ç”¨æˆ·åœ¨è¿‡å»15åˆ†é’Ÿå†…æœ‰ {minutes} åˆ†é’Ÿå¤„äºç–²åŠ³çŠ¶æ€ã€‚è¯·ç»™å‡ºç®€çŸ­çš„ä¼‘æ¯å»ºè®®ï¼Œè¯­æ°”è¦å…³æ€€ã€‚"
            trigger = True
            
        # ä¼˜å…ˆçº§ 2: é«˜åº¦ä¸“æ³¨è¶‹åŠ¿
        elif focused_duration > FOCUS_THRESHOLD and time_since_last > 300:
            minutes = int(focused_duration / 60)
            # åªæœ‰åœ¨éå…æ‰“æ‰°æ¨¡å¼ä¸‹ï¼Œæˆ–è€…ä¸“æ³¨åˆšç»“æŸæ—¶æ‰å¤¸å¥–ï¼Œé¿å…æ‰“æ–­å¿ƒæµ
            # è¿™é‡Œç®€å•å¤„ç†ï¼šå¦‚æœä¸“æ³¨æ—¶é—´å¾ˆé•¿ï¼Œç»™ä¸ªè½»è½»çš„å¤¸å¥–
            if not self.in_dnd_mode:
                msg = f"ç”¨æˆ·åœ¨è¿‡å»15åˆ†é’Ÿå†…ä¿æŒäº† {minutes} åˆ†é’Ÿçš„é«˜æ•ˆä¸“æ³¨ã€‚è¯·ç»™äºˆç®€çŸ­çš„è¡¨æ‰¬å’Œé¼“åŠ±ã€‚"
                trigger = True

        # ä¼˜å…ˆçº§ 3: ç¬æ—¶æ‰“å“ˆæ¬  (é™ä½é¢‘ç‡ï¼Œè‡³å°‘é—´éš”60ç§’)
        elif self.current_status == "Yawning" and time_since_last > 60:
            msg = "ç”¨æˆ·åˆšæ‰æ‰“äº†ä¸ªå“ˆæ¬ ã€‚è¯·ç”¨å¹½é»˜çš„æ–¹å¼æé†’ç”¨æˆ·æ³¨æ„ç²¾åŠ›ç®¡ç†ã€‚"
            trigger = True
            
        if trigger:
            print(f"ğŸ¤– è§¦å‘ AI: {msg}")
            self.last_ai_trigger_time = current_time
            # å¯åŠ¨ AI çº¿ç¨‹
            self.ai_thread = AIThread(msg)
            self.ai_thread.response_received.connect(self.show_ai_message)
            self.ai_thread.start()
            
        # 4. è‡ªåŠ¨å®šæœŸæŠ¥å‘Š (æ¯30åˆ†é’Ÿ / 1800ç§’)
        if current_time - self.last_report_time > 1800:
            print("ğŸ“Š è§¦å‘è‡ªåŠ¨å®šæœŸæŠ¥å‘Š...")
            self.last_report_time = current_time
            self.report_thread = ReportThread()
            self.report_thread.finished.connect(lambda msg: self.bubble.show_message(msg, 5000))
            self.report_thread.start()

    def show_ai_message(self, text):
        # æ ¸å¿ƒé€»è¾‘ï¼šç›´æ¥æ˜¾ç¤ºï¼Œä¸éœ€è¦ç‚¹å‡»
        # è°ƒç”¨ BubbleLabel çš„ show_message æ–¹æ³•ï¼Œå®ƒä¼šè‡ªåŠ¨å¼¹çª—
        self.bubble.show_message(text, duration=10000) # æ˜¾ç¤º10ç§’ï¼Œè®©ç”¨æˆ·æœ‰è¶³å¤Ÿæ—¶é—´çœ‹

    # ================= é¼ æ ‡äº‹ä»¶ (æ‹–æ‹½) =================
    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.offset = event.globalPosition().toPoint() - self.pos()
            self.setCursor(QCursor(Qt.CursorShape.ClosedHandCursor))

    def mouseMoveEvent(self, event):
        if self.dragging:
            self.move(event.globalPosition().toPoint() - self.offset)

    def mouseReleaseEvent(self, event):
        self.dragging = False
        self.setCursor(QCursor(Qt.CursorShape.ArrowCursor))
        
    def show_menu(self, pos):
        menu = QMenu(self)
        
        stats_action = QAction("ğŸ“Š æ‰“å¼€æ•°æ®ç»Ÿè®¡ (Web)", self)
        stats_action.triggered.connect(self.open_web_stats)
        menu.addAction(stats_action)
        
        quit_action = QAction("âŒ é€€å‡º Vigil", self)
        quit_action.triggered.connect(self.close)
        menu.addAction(quit_action)
        
        test_ai_action = QAction("ğŸ¤– æµ‹è¯• AI å¯¹è¯", self)
        test_ai_action.triggered.connect(self.test_ai_dialog)
        menu.addAction(test_ai_action)
        
        menu.exec(self.mapToGlobal(pos))
        
    def test_ai_dialog(self):
        self.bubble.show_message("ğŸ¤– æµ‹è¯•æˆåŠŸï¼æˆ‘æ˜¯ Vigilï¼Œä½ çš„ç²¾åŠ›å®ˆæŠ¤è€…ã€‚æˆ‘ä¼šåœ¨è¿™é‡Œç»™ä½ å‘é€ä¼‘æ¯å»ºè®®å’Œä¸“æ³¨é¼“åŠ±ã€‚", 5000)

    def open_web_stats(self):
        # å¯åŠ¨ Streamlit çœ‹æ¿ (åªè¯»æ¨¡å¼)
        import subprocess
        # è¿™é‡Œåªæ˜¯ç®€å•æ‰“å¼€ï¼Œå®é™…åœºæ™¯å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è”åŠ¨
        subprocess.Popen(["streamlit", "run", "app.py"])

    def closeEvent(self, event):
        self.video_thread.stop()
        event.accept()

if __name__ == "__main__":
    app = QApplication(sys.argv)
    pet = DesktopPet()
    pet.show()
    sys.exit(app.exec())